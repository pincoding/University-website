from fastapi import FastAPI
from pydantic import BaseModel
from openai import OpenAI
from fastapi.middleware.cors import CORSMiddleware
import os
from dotenv import load_dotenv # â­ 1. dotenv ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

load_dotenv() # â­ 2. .env íŒŒì¼ì„ ì½ì–´ í™˜ê²½ ë³€ìˆ˜ë¡œ ë¡œë“œ

app = FastAPI()

# ğŸš¨ API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì•ˆì „í•˜ê²Œ ì½ì–´ì˜µë‹ˆë‹¤. (ì½”ë“œì— í‚¤ ë…¸ì¶œ ì—†ìŒ)
# 3. í•˜ë“œì½”ë”©ëœ í‚¤ë¥¼ os.environ.get()ìœ¼ë¡œ ëŒ€ì²´
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY")) 
FINE_TUNED_MODEL = "ft:gpt-3.5-turbo-0125:personal::Cmop8cxB" 

# CORS ì„¤ì • (ë¦¬ì•¡íŠ¸ ê¸°ë³¸ í¬íŠ¸ 3000 í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
async def chat_endpoint(req: ChatRequest):
    """ë¦¬ì•¡íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ë¥¼ ë°›ì•„ OpenAI APIì— ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        response = client.chat.completions.create(
            model=FINE_TUNED_MODEL,
            messages=[
                # ì‹œìŠ¤í…œ ì—­í• ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
                {"role": "system", "content": "ë„ˆëŠ” í•œêµ­êµí†µëŒ€í•™êµì˜ í•™ì‚¬, ê³µì§€ì‚¬í•­, ì…ì‹œ ì •ë³´ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì•ˆë‚´í•˜ëŠ” ì¹œì ˆí•œ ìƒë‹´ì›ì´ì•¼."},
                {"role": "user", "content": req.message}
            ]
        )
        return {"reply": response.choices[0].message.content}
    except Exception as e:
        print(f"OpenAI API ì—ëŸ¬: {e}")
        return {"error": "API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}, 500